package edu.stanford.nlp.pipeline;

import static org.junit.Assert.*;
import static org.mockito.Mockito.*;

import edu.stanford.nlp.ie.AbstractSequenceClassifier;
import edu.stanford.nlp.ling.*;
import edu.stanford.nlp.parser.lexparser.*;
import edu.stanford.nlp.trees.*;
import edu.stanford.nlp.trees.international.pennchinese.*;
import edu.stanford.nlp.util.CoreMap;
import edu.stanford.nlp.util.PropertiesUtils;
import java.util.*;
import org.junit.Test;

public class ChineseSegmenterAnnotator_5_GPTLLMTest {

  @Test(expected = RuntimeException.class)
  public void testConstructorThrowsWhenModelMissing() {
    Properties props = new Properties();
    new ChineseSegmenterAnnotator("segment", props);
  }

  @Test
  public void testSimpleAnnotationWithMockedSegmentation() {
    String inputText = "ÊàëÁà±Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ";
    AbstractSequenceClassifier<?> mockClassifier = mock(AbstractSequenceClassifier.class);
    List<String> segmented = Arrays.asList("Êàë", "Áà±", "Ëá™ÁÑ∂", "ËØ≠Ë®Ä", "Â§ÑÁêÜ");
    when(mockClassifier.segmentString(inputText)).thenReturn(segmented);
    Properties props = PropertiesUtils.asProperties("segment.model", "dummy-path");
    props.setProperty("segment.verbose", "false");
    ChineseSegmenterAnnotator annotator = new ChineseSegmenterAnnotator("segment", props);
    CoreMap sentence = mock(CoreMap.class);
    when(sentence.get(CoreAnnotations.TextAnnotation.class)).thenReturn(inputText);
    Annotation ann = new Annotation(inputText);
    ann.set(CoreAnnotations.SentencesAnnotation.class, Collections.singletonList(sentence));
    ChineseSegmenterAnnotator spyAnnotator = spy(annotator);
    // doReturn(mockClassifier).when(spyAnnotator).segmenter;
    spyAnnotator.annotate(ann);
    verify(sentence).set(eq(CoreAnnotations.TokensAnnotation.class), any());
  }

  @Test
  public void testNewlineSegmentationEnabled() {
    String input = "ÊàëÁà±\nËá™ÁÑ∂";
    AbstractSequenceClassifier<?> mockClassifier = mock(AbstractSequenceClassifier.class);
    List<String> part1 = Arrays.asList("Êàë", "Áà±");
    List<String> part2 = Arrays.asList("Ëá™ÁÑ∂");
    when(mockClassifier.segmentString("ÊàëÁà±")).thenReturn(part1);
    when(mockClassifier.segmentString("Ëá™ÁÑ∂")).thenReturn(part2);
    Properties props =
        PropertiesUtils.asProperties(
            "segment.model", "dummy", StanfordCoreNLP.NEWLINE_SPLITTER_PROPERTY, "true");
    ChineseSegmenterAnnotator annotator = new ChineseSegmenterAnnotator("segment", props);
    Annotation annotation = new Annotation(input);
    CoreMap sentence = mock(CoreMap.class);
    when(sentence.get(CoreAnnotations.TextAnnotation.class)).thenReturn(input);
    annotation.set(CoreAnnotations.SentencesAnnotation.class, Collections.singletonList(sentence));
    ChineseSegmenterAnnotator spyAnnotator = spy(annotator);
    // doReturn(mockClassifier).when(spyAnnotator).segmenter;
    spyAnnotator.annotate(annotation);
    verify(sentence).set(eq(CoreAnnotations.TokensAnnotation.class), any());
  }

  @Test
  public void testXMLPreservedInSegmentationFlow() {
    String inputText = "<xml>ÊàëÁà±</xml>‰∏≠Êñá";
    AbstractSequenceClassifier<?> mockClassifier = mock(AbstractSequenceClassifier.class);
    when(mockClassifier.segmentString("ÊàëÁà±‰∏≠Êñá")).thenReturn(Arrays.asList("Êàë", "Áà±", "‰∏≠Êñá"));
    Properties props = PropertiesUtils.asProperties("segment.model", "dummy");
    ChineseSegmenterAnnotator annotator = new ChineseSegmenterAnnotator("segment", props);
    CoreMap sentence = mock(CoreMap.class);
    when(sentence.get(CoreAnnotations.TextAnnotation.class)).thenReturn(inputText);
    Annotation annotation = new Annotation(inputText);
    annotation.set(CoreAnnotations.SentencesAnnotation.class, Collections.singletonList(sentence));
    ChineseSegmenterAnnotator spyAnnotator = spy(annotator);
    // doReturn(mockClassifier).when(spyAnnotator).segmenter;
    spyAnnotator.annotate(annotation);
    verify(sentence).set(eq(CoreAnnotations.TokensAnnotation.class), any());
  }

  @Test
  public void testRequirementsSatisfiedContainsExpectedAnnotations() {
    Properties props = PropertiesUtils.asProperties("segment.model", "dummy");
    ChineseSegmenterAnnotator annotator = new ChineseSegmenterAnnotator("segment", props);
    // Set<Class<? extends CoreAnnotations.CoreAnnotation>> result =
    // annotator.requirementsSatisfied();
    // assertTrue(result.contains(CoreAnnotations.TextAnnotation.class));
    // assertTrue(result.contains(CoreAnnotations.TokensAnnotation.class));
    // assertTrue(result.contains(CoreAnnotations.OriginalTextAnnotation.class));
    // assertTrue(result.contains(CoreAnnotations.CharacterOffsetBeginAnnotation.class));
    // assertTrue(result.contains(CoreAnnotations.CharacterOffsetEndAnnotation.class));
  }

  @Test
  public void testRequirementsAreEmpty() {
    Properties props = PropertiesUtils.asProperties("segment.model", "dummy");
    ChineseSegmenterAnnotator annotator = new ChineseSegmenterAnnotator("segment", props);
    // Set<Class<? extends CoreAnnotations.CoreAnnotation>> result = annotator.requires();
    // assertTrue(result.isEmpty());
  }

  @Test
  public void testSegmentationOutputTokenFieldsSet() {
    String input = "Âåó‰∫¨Ê¨¢Ëøé‰Ω†";
    AbstractSequenceClassifier<?> mockClassifier = mock(AbstractSequenceClassifier.class);
    List<String> segmentResults = Arrays.asList("Âåó‰∫¨", "Ê¨¢Ëøé", "‰Ω†");
    when(mockClassifier.segmentString("Âåó‰∫¨Ê¨¢Ëøé‰Ω†")).thenReturn(segmentResults);
    Properties props = PropertiesUtils.asProperties("segment.model", "dummy");
    ChineseSegmenterAnnotator annotator = new ChineseSegmenterAnnotator("segment", props);
    Annotation document = new Annotation(input);
    CoreMap sentence = mock(CoreMap.class);
    when(sentence.get(CoreAnnotations.TextAnnotation.class)).thenReturn(input);
    document.set(CoreAnnotations.SentencesAnnotation.class, Arrays.asList(sentence));
    ChineseSegmenterAnnotator spyAnnotator = spy(annotator);
    // doReturn(mockClassifier).when(spyAnnotator).segmenter;
    spyAnnotator.annotate(document);
    verify(sentence)
        .set(
            eq(CoreAnnotations.TokensAnnotation.class),
            argThat(
                tokens -> {
                  if (!(tokens instanceof List)) return false;
                  List<?> list = (List<?>) tokens;
                  if (list.size() != 3) return false;
                  CoreLabel t0 = (CoreLabel) list.get(0);
                  CoreLabel t1 = (CoreLabel) list.get(1);
                  CoreLabel t2 = (CoreLabel) list.get(2);
                  return "Âåó‰∫¨".equals(t0.word()) && "Ê¨¢Ëøé".equals(t1.word()) && "‰Ω†".equals(t2.word());
                }));
  }

  @Test
  public void testRunSegmentationWithNewlinesRemovedWhenDisabled() {
    String input = "‰ªäÂ§©Â§©Ê∞î\nÂæàÂ•Ω";
    AbstractSequenceClassifier<?> mockClassifier = mock(AbstractSequenceClassifier.class);
    when(mockClassifier.segmentString("‰ªäÂ§©Â§©Ê∞îÂæàÂ•Ω")).thenReturn(Arrays.asList("‰ªäÂ§©Â§©Ê∞î", "ÂæàÂ•Ω"));
    Properties props = PropertiesUtils.asProperties("segment.model", "dummy");
    ChineseSegmenterAnnotator annotator = new ChineseSegmenterAnnotator("segment", props);
    Annotation annotation = new Annotation(input);
    CoreMap sentence = mock(CoreMap.class);
    when(sentence.get(CoreAnnotations.TextAnnotation.class)).thenReturn(input);
    annotation.set(CoreAnnotations.SentencesAnnotation.class, Collections.singletonList(sentence));
    ChineseSegmenterAnnotator spyAnnotator = spy(annotator);
    // doReturn(mockClassifier).when(spyAnnotator).segmenter;
    spyAnnotator.annotate(annotation);
    verify(sentence).set(eq(CoreAnnotations.TokensAnnotation.class), any());
  }

  @Test
  public void testAnnotateHandlesNullSentencesAnnotation() {
    String input = "ÊàëÁà±Âåó‰∫¨";
    AbstractSequenceClassifier<?> mockClassifier = mock(AbstractSequenceClassifier.class);
    List<String> segmented = Arrays.asList("Êàë", "Áà±", "Âåó‰∫¨");
    when(mockClassifier.segmentString("ÊàëÁà±Âåó‰∫¨")).thenReturn(segmented);
    Properties props = PropertiesUtils.asProperties("segment.model", "dummy");
    ChineseSegmenterAnnotator annotator = new ChineseSegmenterAnnotator("segment", props);
    Annotation annotation = new Annotation(input);
    ChineseSegmenterAnnotator spyAnnotator = spy(annotator);
    // doReturn(mockClassifier).when(spyAnnotator).segmenter;
    spyAnnotator.annotate(annotation);
    List<CoreLabel> tokens = annotation.get(CoreAnnotations.TokensAnnotation.class);
    assertNotNull(tokens);
    assertEquals(3, tokens.size());
    assertEquals("Êàë", tokens.get(0).word());
    assertEquals("Áà±", tokens.get(1).word());
    assertEquals("Âåó‰∫¨", tokens.get(2).word());
  }

  @Test
  public void testSplitCharactersSkipsLeadingAndTrailingNewlines() {
    String input = "\n\nÊàëÁà±‰∏≠Êñá\n\n";
    AbstractSequenceClassifier<?> mockClassifier = mock(AbstractSequenceClassifier.class);
    when(mockClassifier.segmentString("ÊàëÁà±‰∏≠Êñá")).thenReturn(Arrays.asList("Êàë", "Áà±", "‰∏≠Êñá"));
    Properties props =
        PropertiesUtils.asProperties(
            "segment.model", "dummy", StanfordCoreNLP.NEWLINE_SPLITTER_PROPERTY, "true");
    ChineseSegmenterAnnotator annotator = new ChineseSegmenterAnnotator("segment", props);
    Annotation annotation = new Annotation(input);
    CoreMap sentence = mock(CoreMap.class);
    when(sentence.get(CoreAnnotations.TextAnnotation.class)).thenReturn(input);
    annotation.set(CoreAnnotations.SentencesAnnotation.class, Collections.singletonList(sentence));
    ChineseSegmenterAnnotator spyAnnotator = spy(annotator);
    // doReturn(mockClassifier).when(spyAnnotator).segmenter;
    spyAnnotator.annotate(annotation);
    verify(sentence)
        .set(
            eq(CoreAnnotations.TokensAnnotation.class),
            argThat(
                tokens -> {
                  if (!(tokens instanceof List)) return false;
                  List<?> list = (List<?>) tokens;
                  return list.size() == 3;
                }));
  }

  @Test
  public void testSingleNewlineInMiddleRemovedWhenSentenceSplitOnTwoNewlines() {
    String input = "‰ªñ\nÊù•‰∫Ü";
    AbstractSequenceClassifier<?> mockClassifier = mock(AbstractSequenceClassifier.class);
    when(mockClassifier.segmentString("‰ªñÊù•‰∫Ü")).thenReturn(Arrays.asList("‰ªñ", "Êù•‰∫Ü"));
    Properties props =
        PropertiesUtils.asProperties(
            "segment.model", "dummy", StanfordCoreNLP.NEWLINE_IS_SENTENCE_BREAK_PROPERTY, "two");
    ChineseSegmenterAnnotator annotator = new ChineseSegmenterAnnotator("segment", props);
    Annotation annotation = new Annotation(input);
    CoreMap sentence = mock(CoreMap.class);
    when(sentence.get(CoreAnnotations.TextAnnotation.class)).thenReturn(input);
    annotation.set(CoreAnnotations.SentencesAnnotation.class, Collections.singletonList(sentence));
    ChineseSegmenterAnnotator spyAnnotator = spy(annotator);
    // doReturn(mockClassifier).when(spyAnnotator).segmenter;
    spyAnnotator.annotate(annotation);
    verify(sentence)
        .set(
            eq(CoreAnnotations.TokensAnnotation.class),
            argThat(
                tokens -> {
                  if (!(tokens instanceof List)) return false;
                  List<?> list = (List<?>) tokens;
                  return list.size() == 2;
                }));
  }

  @Test
  public void testMakeXmlTokenNormalizesSpacesWhenEnabled() {
    Properties props =
        PropertiesUtils.asProperties("segment.model", "dummy", "segment.normalizeSpace", "true");
    ChineseSegmenterAnnotator annotator = new ChineseSegmenterAnnotator("segment", props);
    CoreLabel token = new CoreLabel();
    token.setOriginalText("a b");
    String inputText = "a b";
    Annotation ann = new Annotation(inputText);
    CoreMap sentence = mock(CoreMap.class);
    when(sentence.get(CoreAnnotations.TextAnnotation.class)).thenReturn(inputText);
    ann.set(CoreAnnotations.SentencesAnnotation.class, Collections.singletonList(sentence));
    AbstractSequenceClassifier<?> mockClassifier = mock(AbstractSequenceClassifier.class);
    when(mockClassifier.segmentString("a b")).thenReturn(Collections.singletonList("a b"));
    ChineseSegmenterAnnotator spy = spy(annotator);
    // doReturn(mockClassifier).when(spy).segmenter;
    spy.annotate(ann);
    verify(sentence)
        .set(
            eq(CoreAnnotations.TokensAnnotation.class),
            argThat(
                tokens -> {
                  if (!(tokens instanceof List)) return false;
                  CoreLabel label = (CoreLabel) ((List<?>) tokens).get(0);
                  return label.word().contains("\u00A0");
                }));
  }

  @Test
  public void testMakeXmlTokenMapsBlankLineToSpecialToken() {
    String newline = "\n";
    AbstractSequenceClassifier<?> mockClassifier = mock(AbstractSequenceClassifier.class);
    when(mockClassifier.segmentString("")).thenReturn(Collections.singletonList(newline));
    Properties props =
        PropertiesUtils.asProperties(
            "segment.model", "dummy", StanfordCoreNLP.NEWLINE_SPLITTER_PROPERTY, "true");
    ChineseSegmenterAnnotator annotator = new ChineseSegmenterAnnotator("segment", props);
    String inputText = "\n";
    Annotation ann = new Annotation(inputText);
    CoreMap sentence = mock(CoreMap.class);
    when(sentence.get(CoreAnnotations.TextAnnotation.class)).thenReturn(inputText);
    ann.set(CoreAnnotations.SentencesAnnotation.class, Collections.singletonList(sentence));
    ChineseSegmenterAnnotator spy = spy(annotator);
    // doReturn(mockClassifier).when(spy).segmenter;
    spy.annotate(ann);
    verify(sentence)
        .set(
            eq(CoreAnnotations.TokensAnnotation.class),
            argThat(
                tokens -> {
                  if (!(tokens instanceof List)) return false;
                  CoreLabel label = (CoreLabel) ((List<?>) tokens).get(0);
                  return "\n".equals(label.originalText())
                      || "[CR]".equals(label.word())
                      || "\n".equals(label.word());
                }));
  }

  @Test
  public void testSegmentXmlElementAndPlainTextMixedCorrectly() {
    String input = "<tag>‰∏≠Êñá</tag>ÂíåËã±Êñá";
    AbstractSequenceClassifier<?> mockClassifier = mock(AbstractSequenceClassifier.class);
    when(mockClassifier.segmentString("‰∏≠ÊñáÂíåËã±Êñá")).thenReturn(Arrays.asList("‰∏≠Êñá", "Âíå", "Ëã±Êñá"));
    Properties props = PropertiesUtils.asProperties("segment.model", "dummy");
    ChineseSegmenterAnnotator annotator = new ChineseSegmenterAnnotator("segment", props);
    Annotation annotation = new Annotation(input);
    CoreMap sentence = mock(CoreMap.class);
    when(sentence.get(CoreAnnotations.TextAnnotation.class)).thenReturn(input);
    annotation.set(CoreAnnotations.SentencesAnnotation.class, Collections.singletonList(sentence));
    ChineseSegmenterAnnotator spy = spy(annotator);
    // doReturn(mockClassifier).when(spy).segmenter;
    spy.annotate(annotation);
    verify(sentence)
        .set(
            eq(CoreAnnotations.TokensAnnotation.class),
            argThat(
                tokens -> {
                  if (!(tokens instanceof List)) return false;
                  List<CoreLabel> list = (List<CoreLabel>) tokens;
                  if (list.size() < 4) return false;
                  boolean hasXml = false;
                  boolean hasTextToken = false;
                  for (CoreLabel token : list) {
                    if (token.originalText() != null && token.originalText().startsWith("<tag>"))
                      hasXml = true;
                    if ("‰∏≠Êñá".equals(token.word())
                        || "Âíå".equals(token.word())
                        || "Ëã±Êñá".equals(token.word())) hasTextToken = true;
                  }
                  return hasXml && hasTextToken;
                }));
  }

  @Test
  public void testAnnotateHandlesEmptyStringWithoutError() {
    AbstractSequenceClassifier<?> mockClassifier = mock(AbstractSequenceClassifier.class);
    when(mockClassifier.segmentString("")).thenReturn(Collections.emptyList());
    Properties props = PropertiesUtils.asProperties("segment.model", "dummy");
    ChineseSegmenterAnnotator annotator = new ChineseSegmenterAnnotator("segment", props);
    Annotation annotation = new Annotation("");
    CoreMap sentence = mock(CoreMap.class);
    when(sentence.get(CoreAnnotations.TextAnnotation.class)).thenReturn("");
    annotation.set(CoreAnnotations.SentencesAnnotation.class, Collections.singletonList(sentence));
    ChineseSegmenterAnnotator spy = spy(annotator);
    // doReturn(mockClassifier).when(spy).segmenter;
    spy.annotate(annotation);
    verify(sentence)
        .set(
            eq(CoreAnnotations.TokensAnnotation.class),
            argThat(
                tokens -> {
                  return tokens instanceof List && ((List<?>) tokens).isEmpty();
                }));
  }

  @Test
  public void testSingleSpaceCharacterIsSkippedInSplitCharacters() {
    String inputText = "Êàë Áà±";
    AbstractSequenceClassifier<?> mockSegmenter = mock(AbstractSequenceClassifier.class);
    when(mockSegmenter.segmentString("ÊàëÁà±")).thenReturn(Arrays.asList("Êàë", "Áà±"));
    Properties props = PropertiesUtils.asProperties("segment.model", "dummy");
    ChineseSegmenterAnnotator annotator = new ChineseSegmenterAnnotator("segment", props);
    CoreMap sentence = mock(CoreMap.class);
    when(sentence.get(CoreAnnotations.TextAnnotation.class)).thenReturn(inputText);
    Annotation annotation = new Annotation(inputText);
    annotation.set(CoreAnnotations.SentencesAnnotation.class, Collections.singletonList(sentence));
    ChineseSegmenterAnnotator spy = spy(annotator);
    // doReturn(mockSegmenter).when(spy).segmenter;
    spy.annotate(annotation);
    verify(sentence)
        .set(
            eq(CoreAnnotations.TokensAnnotation.class),
            argThat(
                tokens -> {
                  if (!(tokens instanceof List)) return false;
                  List list = (List) tokens;
                  return list.size() == 2;
                }));
  }

  @Test
  public void testXmlWhitespaceTokensAreHandledCorrectly() {
    String inputText = "<tag>\n</tag>ÊµãËØï";
    AbstractSequenceClassifier<?> mockSegmenter = mock(AbstractSequenceClassifier.class);
    when(mockSegmenter.segmentString("ÊµãËØï")).thenReturn(Arrays.asList("ÊµãËØï"));
    Properties props = PropertiesUtils.asProperties("segment.model", "dummy");
    ChineseSegmenterAnnotator annotator = new ChineseSegmenterAnnotator("segment", props);
    CoreMap sentence = mock(CoreMap.class);
    when(sentence.get(CoreAnnotations.TextAnnotation.class)).thenReturn(inputText);
    Annotation annotation = new Annotation(inputText);
    annotation.set(CoreAnnotations.SentencesAnnotation.class, Collections.singletonList(sentence));
    ChineseSegmenterAnnotator spy = spy(annotator);
    // doReturn(mockSegmenter).when(spy).segmenter;
    spy.annotate(annotation);
    verify(sentence)
        .set(
            eq(CoreAnnotations.TokensAnnotation.class),
            argThat(
                tokens -> {
                  if (!(tokens instanceof List)) return false;
                  List<CoreLabel> list = (List<CoreLabel>) tokens;
                  boolean foundXml = false;
                  boolean foundText = false;
                  for (int i = 0; i < list.size(); i++) {
                    CoreLabel t = list.get(i);
                    if (t.originalText() != null && t.originalText().contains("<tag>")) {
                      foundXml = true;
                    }
                    if ("ÊµãËØï".equals(t.word())) {
                      foundText = true;
                    }
                  }
                  return foundXml && foundText;
                }));
  }

  @Test
  public void testHandlesNonBmpCharactersCorrectly() {
    String inputText = "ÊàëüòÄ‰Ω†";
    AbstractSequenceClassifier<?> mockSegmenter = mock(AbstractSequenceClassifier.class);
    when(mockSegmenter.segmentString("ÊàëüòÄ‰Ω†")).thenReturn(Arrays.asList("Êàë", "üòÄ", "‰Ω†"));
    Properties props = PropertiesUtils.asProperties("segment.model", "dummy");
    ChineseSegmenterAnnotator annotator = new ChineseSegmenterAnnotator("segment", props);
    CoreMap sentence = mock(CoreMap.class);
    when(sentence.get(CoreAnnotations.TextAnnotation.class)).thenReturn(inputText);
    Annotation annotation = new Annotation(inputText);
    annotation.set(CoreAnnotations.SentencesAnnotation.class, Collections.singletonList(sentence));
    ChineseSegmenterAnnotator spy = spy(annotator);
    // doReturn(mockSegmenter).when(spy).segmenter;
    spy.annotate(annotation);
    verify(sentence)
        .set(
            eq(CoreAnnotations.TokensAnnotation.class),
            argThat(
                tokens -> {
                  if (!(tokens instanceof List)) return false;
                  List list = (List) tokens;
                  if (list.size() != 3) return false;
                  CoreLabel t0 = (CoreLabel) list.get(0);
                  CoreLabel t1 = (CoreLabel) list.get(1);
                  CoreLabel t2 = (CoreLabel) list.get(2);
                  return "Êàë".equals(t0.word()) && "üòÄ".equals(t1.word()) && "‰Ω†".equals(t2.word());
                }));
  }

  @Test
  public void testHandlesConsecutiveNewlinesInNewlineSplitterMode() {
    String inputText = "Êàë\n\n‰Ω†";
    AbstractSequenceClassifier<?> mockSegmenter = mock(AbstractSequenceClassifier.class);
    when(mockSegmenter.segmentString("Êàë")).thenReturn(Arrays.asList("Êàë"));
    when(mockSegmenter.segmentString("‰Ω†")).thenReturn(Arrays.asList("‰Ω†"));
    Properties props =
        PropertiesUtils.asProperties(
            "segment.model", "dummy", StanfordCoreNLP.NEWLINE_SPLITTER_PROPERTY, "true");
    ChineseSegmenterAnnotator annotator = new ChineseSegmenterAnnotator("segment", props);
    CoreMap sentence = mock(CoreMap.class);
    when(sentence.get(CoreAnnotations.TextAnnotation.class)).thenReturn(inputText);
    Annotation annotation = new Annotation(inputText);
    annotation.set(CoreAnnotations.SentencesAnnotation.class, Collections.singletonList(sentence));
    ChineseSegmenterAnnotator spy = spy(annotator);
    // doReturn(mockSegmenter).when(spy).segmenter;
    spy.annotate(annotation);
    verify(sentence)
        .set(
            eq(CoreAnnotations.TokensAnnotation.class),
            argThat(
                tokens -> {
                  if (!(tokens instanceof List)) return false;
                  List<CoreLabel> list = (List<CoreLabel>) tokens;
                  boolean hasNewlineToken = false;
                  for (int i = 0; i < list.size(); i++) {
                    CoreLabel token = list.get(i);
                    // if ("\n".equals(token.originalText()) ||
                    // AbstractSequenceClassifier.NEWLINE_TOKEN.equals(token.word())) {
                    // hasNewlineToken = true;
                    // }
                  }
                  return list.size() >= 3 && hasNewlineToken;
                }));
  }

  @Test
  public void testHandlesAllWhitespaceTextWithoutError() {
    String inputText = "   \n ";
    AbstractSequenceClassifier<?> mockSegmenter = mock(AbstractSequenceClassifier.class);
    when(mockSegmenter.segmentString(anyString())).thenReturn(Collections.emptyList());
    Properties props = PropertiesUtils.asProperties("segment.model", "dummy");
    ChineseSegmenterAnnotator annotator = new ChineseSegmenterAnnotator("segment", props);
    CoreMap sentence = mock(CoreMap.class);
    when(sentence.get(CoreAnnotations.TextAnnotation.class)).thenReturn(inputText);
    Annotation annotation = new Annotation(inputText);
    annotation.set(CoreAnnotations.SentencesAnnotation.class, Collections.singletonList(sentence));
    ChineseSegmenterAnnotator spy = spy(annotator);
    // doReturn(mockSegmenter).when(spy).segmenter;
    spy.annotate(annotation);
    verify(sentence)
        .set(
            eq(CoreAnnotations.TokensAnnotation.class),
            argThat(
                tokens -> {
                  return tokens instanceof List && ((List<?>) tokens).isEmpty();
                }));
  }

  @Test
  public void testEndOffsetIsCorrectAfterSegmentation() {
    String inputText = "Ëá™ÁÑ∂ËØ≠Ë®Ä";
    AbstractSequenceClassifier<?> mockSegmenter = mock(AbstractSequenceClassifier.class);
    when(mockSegmenter.segmentString("Ëá™ÁÑ∂ËØ≠Ë®Ä")).thenReturn(Arrays.asList("Ëá™ÁÑ∂", "ËØ≠Ë®Ä"));
    Properties props = PropertiesUtils.asProperties("segment.model", "dummy");
    ChineseSegmenterAnnotator annotator = new ChineseSegmenterAnnotator("segment", props);
    CoreMap sentence = mock(CoreMap.class);
    when(sentence.get(CoreAnnotations.TextAnnotation.class)).thenReturn(inputText);
    Annotation annotation = new Annotation(inputText);
    annotation.set(CoreAnnotations.SentencesAnnotation.class, Collections.singletonList(sentence));
    ChineseSegmenterAnnotator spy = spy(annotator);
    // doReturn(mockSegmenter).when(spy).segmenter;
    spy.annotate(annotation);
    verify(sentence)
        .set(
            eq(CoreAnnotations.TokensAnnotation.class),
            argThat(
                tokens -> {
                  if (!(tokens instanceof List)) return false;
                  List<CoreLabel> list = (List<CoreLabel>) tokens;
                  if (list.size() != 2) return false;
                  CoreLabel t1 = list.get(0);
                  CoreLabel t2 = list.get(1);
                  Integer end1 = t1.get(CoreAnnotations.CharacterOffsetEndAnnotation.class);
                  Integer begin2 = t2.get(CoreAnnotations.CharacterOffsetBeginAnnotation.class);
                  return end1.equals(begin2);
                }));
  }

  @Test
  public void testNormalizeSpaceFalseLeavesSpacesUnchanged() {
    String input = "Ê†á  Á≠æ";
    AbstractSequenceClassifier<?> mockClassifier = mock(AbstractSequenceClassifier.class);
    when(mockClassifier.segmentString("Ê†á  Á≠æ")).thenReturn(Collections.singletonList("Ê†á  Á≠æ"));
    Properties props =
        PropertiesUtils.asProperties("segment.model", "dummy", "segment.normalizeSpace", "false");
    ChineseSegmenterAnnotator annotator = new ChineseSegmenterAnnotator("segment", props);
    CoreMap sentence = mock(CoreMap.class);
    when(sentence.get(CoreAnnotations.TextAnnotation.class)).thenReturn(input);
    Annotation annotation = new Annotation(input);
    annotation.set(CoreAnnotations.SentencesAnnotation.class, Collections.singletonList(sentence));
    ChineseSegmenterAnnotator spy = spy(annotator);
    // doReturn(mockClassifier).when(spy).segmenter;
    spy.annotate(annotation);
    verify(sentence)
        .set(
            eq(CoreAnnotations.TokensAnnotation.class),
            argThat(
                tokens -> {
                  List<CoreLabel> list = (List<CoreLabel>) tokens;
                  if (list.isEmpty()) return false;
                  return list.get(0).word().equals("Ê†á  Á≠æ");
                }));
  }

  @Test
  public void testMalformedXmlTagTreatedAsPlainText() {
    String input = "<unclosed ÊàëÁà±‰Ω†";
    AbstractSequenceClassifier<?> classifier = mock(AbstractSequenceClassifier.class);
    when(classifier.segmentString("ÊàëÁà±‰Ω†")).thenReturn(Arrays.asList("Êàë", "Áà±", "‰Ω†"));
    Properties props = PropertiesUtils.asProperties("segment.model", "dummy");
    ChineseSegmenterAnnotator annotator = new ChineseSegmenterAnnotator("segment", props);
    Annotation annotation = new Annotation(input);
    CoreMap sentence = mock(CoreMap.class);
    when(sentence.get(CoreAnnotations.TextAnnotation.class)).thenReturn(input);
    annotation.set(CoreAnnotations.SentencesAnnotation.class, Arrays.asList(sentence));
    ChineseSegmenterAnnotator spy = spy(annotator);
    // doReturn(classifier).when(spy).segmenter;
    spy.annotate(annotation);
    verify(sentence)
        .set(
            eq(CoreAnnotations.TokensAnnotation.class),
            argThat(
                tokens -> {
                  List<?> list = (List<?>) tokens;
                  return !list.isEmpty();
                }));
  }

  @Test
  public void testVeryLastCharInInputCorrectlyTokenized() {
    String input = "‰Ω†";
    AbstractSequenceClassifier<?> classifier = mock(AbstractSequenceClassifier.class);
    when(classifier.segmentString("‰Ω†")).thenReturn(Collections.singletonList("‰Ω†"));
    Properties props = PropertiesUtils.asProperties("segment.model", "dummy");
    ChineseSegmenterAnnotator annotator = new ChineseSegmenterAnnotator("segment", props);
    Annotation annotation = new Annotation(input);
    CoreMap sentence = mock(CoreMap.class);
    when(sentence.get(CoreAnnotations.TextAnnotation.class)).thenReturn(input);
    annotation.set(CoreAnnotations.SentencesAnnotation.class, Arrays.asList(sentence));
    ChineseSegmenterAnnotator spy = spy(annotator);
    // doReturn(classifier).when(spy).segmenter;
    spy.annotate(annotation);
    verify(sentence)
        .set(
            eq(CoreAnnotations.TokensAnnotation.class),
            argThat(
                tokens -> {
                  List<?> list = (List<?>) tokens;
                  if (list.size() != 1) return false;
                  CoreLabel token = (CoreLabel) list.get(0);
                  return "‰Ω†".equals(token.word())
                      && Integer.valueOf(0)
                          .equals(token.get(CoreAnnotations.CharacterOffsetBeginAnnotation.class));
                }));
  }

  @Test
  public void testNewlineTokenSplitTwiceWhenSentenceSplitOnTwoNewlines() {
    String input = "Êó©ÂÆâ\n\nÊôöÂÆâ";
    AbstractSequenceClassifier<?> classifier = mock(AbstractSequenceClassifier.class);
    when(classifier.segmentString("Êó©ÂÆâÊôöÂÆâ")).thenReturn(Arrays.asList("Êó©ÂÆâ", "ÊôöÂÆâ"));
    Properties props =
        PropertiesUtils.asProperties(
            "segment.model", "dummy", StanfordCoreNLP.NEWLINE_IS_SENTENCE_BREAK_PROPERTY, "two");
    ChineseSegmenterAnnotator annotator = new ChineseSegmenterAnnotator("segment", props);
    Annotation annotation = new Annotation(input);
    CoreMap sentence = mock(CoreMap.class);
    when(sentence.get(CoreAnnotations.TextAnnotation.class)).thenReturn(input);
    annotation.set(CoreAnnotations.SentencesAnnotation.class, Arrays.asList(sentence));
    ChineseSegmenterAnnotator spy = spy(annotator);
    // doReturn(classifier).when(spy).segmenter;
    spy.annotate(annotation);
    verify(sentence)
        .set(
            eq(CoreAnnotations.TokensAnnotation.class),
            argThat(
                tokens -> {
                  List<?> list = (List<?>) tokens;
                  return list.size() == 2;
                }));
  }

  @Test
  public void testControlCharactersInInputAreSkipped() {
    String input = "‰Ω†\u0001Â•Ω";
    AbstractSequenceClassifier<?> classifier = mock(AbstractSequenceClassifier.class);
    when(classifier.segmentString("‰Ω†Â•Ω")).thenReturn(Arrays.asList("‰Ω†", "Â•Ω"));
    Properties props = PropertiesUtils.asProperties("segment.model", "dummy");
    ChineseSegmenterAnnotator annotator = new ChineseSegmenterAnnotator("segment", props);
    Annotation annotation = new Annotation(input);
    CoreMap sentence = mock(CoreMap.class);
    when(sentence.get(CoreAnnotations.TextAnnotation.class)).thenReturn(input);
    annotation.set(CoreAnnotations.SentencesAnnotation.class, Arrays.asList(sentence));
    ChineseSegmenterAnnotator spy = spy(annotator);
    // doReturn(classifier).when(spy).segmenter;
    spy.annotate(annotation);
    verify(sentence)
        .set(
            eq(CoreAnnotations.TokensAnnotation.class),
            argThat(
                tokens -> {
                  return ((List<?>) tokens).size() == 2;
                }));
  }

  @Test
  public void testEmptyStringInSegmenterOutputIsIgnored() {
    String input = "abc";
    AbstractSequenceClassifier<?> classifier = mock(AbstractSequenceClassifier.class);
    when(classifier.segmentString("abc")).thenReturn(Arrays.asList("a", "", "b", "c"));
    Properties props = PropertiesUtils.asProperties("segment.model", "dummy");
    ChineseSegmenterAnnotator annotator = new ChineseSegmenterAnnotator("segment", props);
    Annotation annotation = new Annotation(input);
    CoreMap sentence = mock(CoreMap.class);
    when(sentence.get(CoreAnnotations.TextAnnotation.class)).thenReturn(input);
    annotation.set(CoreAnnotations.SentencesAnnotation.class, Arrays.asList(sentence));
    ChineseSegmenterAnnotator spy = spy(annotator);
    // doReturn(classifier).when(spy).segmenter;
    spy.annotate(annotation);
    verify(sentence)
        .set(
            eq(CoreAnnotations.TokensAnnotation.class),
            argThat(
                tokens -> {
                  List<?> list = (List<?>) tokens;
                  for (Object obj : list) {
                    CoreLabel t = (CoreLabel) obj;
                    if ("".equals(t.word())) return false;
                  }
                  return true;
                }));
  }

  @Test
  public void testOnlyNewlinesAsInputWithNewlineBreak() {
    String input = "\n\n\n";
    AbstractSequenceClassifier<?> classifier = mock(AbstractSequenceClassifier.class);
    when(classifier.segmentString(anyString())).thenReturn(Collections.singletonList("\n"));
    Properties props =
        PropertiesUtils.asProperties(
            "segment.model", "dummy", StanfordCoreNLP.NEWLINE_SPLITTER_PROPERTY, "true");
    ChineseSegmenterAnnotator annotator = new ChineseSegmenterAnnotator("segment", props);
    Annotation annotation = new Annotation(input);
    CoreMap sentence = mock(CoreMap.class);
    when(sentence.get(CoreAnnotations.TextAnnotation.class)).thenReturn(input);
    annotation.set(CoreAnnotations.SentencesAnnotation.class, Arrays.asList(sentence));
    ChineseSegmenterAnnotator spy = spy(annotator);
    // doReturn(classifier).when(spy).segmenter;
    spy.annotate(annotation);
    verify(sentence)
        .set(
            eq(CoreAnnotations.TokensAnnotation.class),
            argThat(
                tokens -> {
                  return !((List<?>) tokens).isEmpty();
                }));
  }

  @Test
  public void testLongXmlFollowedByText() {
    String input = "<tag>\n<data>ignore</data></tag>\nÊµãËØïÊñáÊú¨";
    AbstractSequenceClassifier<?> classifier = mock(AbstractSequenceClassifier.class);
    when(classifier.segmentString("ÊµãËØïÊñáÊú¨")).thenReturn(Arrays.asList("ÊµãËØï", "ÊñáÊú¨"));
    Properties props = PropertiesUtils.asProperties("segment.model", "dummy");
    ChineseSegmenterAnnotator annotator = new ChineseSegmenterAnnotator("segment", props);
    Annotation annotation = new Annotation(input);
    CoreMap sentence = mock(CoreMap.class);
    when(sentence.get(CoreAnnotations.TextAnnotation.class)).thenReturn(input);
    annotation.set(CoreAnnotations.SentencesAnnotation.class, Arrays.asList(sentence));
    ChineseSegmenterAnnotator spy = spy(annotator);
    // doReturn(classifier).when(spy).segmenter;
    spy.annotate(annotation);
    verify(sentence)
        .set(
            eq(CoreAnnotations.TokensAnnotation.class),
            argThat(
                tokens -> {
                  List<CoreLabel> list = (List<CoreLabel>) tokens;
                  boolean hasXml = false;
                  boolean hasText = false;
                  for (CoreLabel t : list) {
                    if (t.originalText() != null && t.originalText().contains("<")) hasXml = true;
                    if ("ÊµãËØï".equals(t.word()) || "ÊñáÊú¨".equals(t.word())) hasText = true;
                  }
                  return hasXml && hasText;
                }));
  }

  @Test
  public void testHandlesBackToBackXmlTagsCorrectly() {
    String input = "<div></div><p></p>‰Ω†Â•Ω";
    AbstractSequenceClassifier<?> classifier = mock(AbstractSequenceClassifier.class);
    when(classifier.segmentString("‰Ω†Â•Ω")).thenReturn(Arrays.asList("‰Ω†", "Â•Ω"));
    Properties props = PropertiesUtils.asProperties("segment.model", "dummy");
    ChineseSegmenterAnnotator annotator = new ChineseSegmenterAnnotator("segment", props);
    Annotation annotation = new Annotation(input);
    CoreMap sentence = mock(CoreMap.class);
    when(sentence.get(CoreAnnotations.TextAnnotation.class)).thenReturn(input);
    annotation.set(CoreAnnotations.SentencesAnnotation.class, Arrays.asList(sentence));
    ChineseSegmenterAnnotator spy = spy(annotator);
    // doReturn(classifier).when(spy).segmenter;
    spy.annotate(annotation);
    verify(sentence)
        .set(
            eq(CoreAnnotations.TokensAnnotation.class),
            argThat(
                tokens -> {
                  List<CoreLabel> list = (List<CoreLabel>) tokens;
                  return list.size() >= 3;
                }));
  }

  @Test
  public void testAdvancePosThrowsForMultiCharMismatch() {
    String input = "ÊàëÁà±‰Ω†";
    CoreLabel cl0 = new CoreLabel();
    cl0.set(CoreAnnotations.ChineseCharAnnotation.class, "Êàë");
    CoreLabel cl1 = new CoreLabel();
    cl1.set(CoreAnnotations.ChineseCharAnnotation.class, "Áà±");
    CoreLabel cl2 = new CoreLabel();
    cl2.set(CoreAnnotations.ChineseCharAnnotation.class, "‰Ω†");
    List<CoreLabel> characters = new ArrayList<>();
    characters.add(cl0);
    characters.add(cl1);
    characters.add(cl2);
    try {
      ChineseSegmenterAnnotator.class
          .getDeclaredMethod("advancePos", List.class, int.class, String.class)
          .invoke(null, characters, 0, "Áà±‰Ω†Êàë");
      fail("Expected exception not thrown");
    } catch (Exception e) {
      Throwable cause = e.getCause();
      assertTrue(cause instanceof RuntimeException);
      assertTrue(cause.getMessage().contains("Ate the whole text without matching"));
    }
  }

  @Test
  public void testXmlPatternSkipsPlainAngleBrackets() {
    String input = "Êàë<‰Ω†>";
    AbstractSequenceClassifier<?> classifier = mock(AbstractSequenceClassifier.class);
    when(classifier.segmentString("Êàë<‰Ω†>")).thenReturn(Collections.singletonList("Êàë<‰Ω†>"));
    Properties props = PropertiesUtils.asProperties("segment.model", "dummy");
    ChineseSegmenterAnnotator annotator = new ChineseSegmenterAnnotator("segment", props);
    Annotation ann = new Annotation(input);
    CoreMap sentence = mock(CoreMap.class);
    when(sentence.get(CoreAnnotations.TextAnnotation.class)).thenReturn(input);
    ann.set(CoreAnnotations.SentencesAnnotation.class, Collections.singletonList(sentence));
    ChineseSegmenterAnnotator spy = spy(annotator);
    // doReturn(classifier).when(spy).segmenter;
    spy.annotate(ann);
    verify(sentence)
        .set(
            eq(CoreAnnotations.TokensAnnotation.class),
            argThat(
                toks -> {
                  List<CoreLabel> list = (List<CoreLabel>) toks;
                  if (list.size() != 1) return false;
                  return list.get(0).word().equals("Êàë<‰Ω†>");
                }));
  }

  @Test
  public void testLongSingleXmlSequenceProcessedAsSingleToken() {
    String input = "<meta charset='utf-8'>";
    AbstractSequenceClassifier<?> classifier = mock(AbstractSequenceClassifier.class);
    when(classifier.segmentString("")).thenReturn(Collections.emptyList());
    Properties props = PropertiesUtils.asProperties("segment.model", "dummy");
    ChineseSegmenterAnnotator annotator = new ChineseSegmenterAnnotator("segment", props);
    Annotation ann = new Annotation(input);
    CoreMap sentence = mock(CoreMap.class);
    when(sentence.get(CoreAnnotations.TextAnnotation.class)).thenReturn(input);
    ann.set(CoreAnnotations.SentencesAnnotation.class, Collections.singletonList(sentence));
    ChineseSegmenterAnnotator spy = spy(annotator);
    // doReturn(classifier).when(spy).segmenter;
    spy.annotate(ann);
    verify(sentence)
        .set(
            eq(CoreAnnotations.TokensAnnotation.class),
            argThat(
                toks -> {
                  List<CoreLabel> list = (List<CoreLabel>) toks;
                  if (list.size() != 1) return false;
                  CoreLabel xml = list.get(0);
                  return xml.originalText().contains("<meta");
                }));
  }

  @Test
  public void testAdvancePosMatchesSingleCodePointCharacters() {
    String input = "‰∏≠ÊñáABC";
    CoreLabel cl0 = new CoreLabel();
    cl0.set(CoreAnnotations.ChineseCharAnnotation.class, "‰∏≠");
    CoreLabel cl1 = new CoreLabel();
    cl1.set(CoreAnnotations.ChineseCharAnnotation.class, "Êñá");
    CoreLabel cl2 = new CoreLabel();
    cl2.set(CoreAnnotations.ChineseCharAnnotation.class, "A");
    CoreLabel cl3 = new CoreLabel();
    cl3.set(CoreAnnotations.ChineseCharAnnotation.class, "B");
    CoreLabel cl4 = new CoreLabel();
    cl4.set(CoreAnnotations.ChineseCharAnnotation.class, "C");
    List<CoreLabel> chars = new ArrayList<>();
    chars.add(cl0);
    chars.add(cl1);
    chars.add(cl2);
    chars.add(cl3);
    chars.add(cl4);
    int next = -1;
    try {
      next =
          (int)
              ChineseSegmenterAnnotator.class
                  .getDeclaredMethod("advancePos", List.class, int.class, String.class)
                  .invoke(null, chars, 0, "‰∏≠Êñá");
    } catch (Exception e) {
      fail("Exception during advancePos");
    }
    assertEquals(2, next);
  }

  @Test
  public void testLineOnlyContainsCRIsIgnoredWhenNewlineSplitIsDisabled() {
    String input = "Êàë\r‰Ω†";
    AbstractSequenceClassifier<?> classifier = mock(AbstractSequenceClassifier.class);
    when(classifier.segmentString("Êàë‰Ω†")).thenReturn(Arrays.asList("Êàë", "‰Ω†"));
    Properties props = PropertiesUtils.asProperties("segment.model", "dummy");
    ChineseSegmenterAnnotator annotator = new ChineseSegmenterAnnotator("segment", props);
    Annotation ann = new Annotation(input);
    CoreMap sentence = mock(CoreMap.class);
    when(sentence.get(CoreAnnotations.TextAnnotation.class)).thenReturn(input);
    ann.set(CoreAnnotations.SentencesAnnotation.class, Collections.singletonList(sentence));
    ChineseSegmenterAnnotator spy = spy(annotator);
    // doReturn(classifier).when(spy).segmenter;
    spy.annotate(ann);
    verify(sentence)
        .set(
            eq(CoreAnnotations.TokensAnnotation.class),
            argThat(
                tokens -> {
                  List<CoreLabel> list = (List<CoreLabel>) tokens;
                  return list.size() == 2;
                }));
  }

  @Test
  public void testThrowsRuntimeExceptionIfRequiredModelFileIsMissing() {
    Properties props = new Properties();
    props.setProperty("segment.unknownKey", "someValue");
    try {
      new ChineseSegmenterAnnotator("segment", props);
      fail("Expected RuntimeException for missing segment.model");
    } catch (RuntimeException ex) {
      assertTrue(ex.getMessage().contains("Expected a property segment.model"));
    }
  }

  @Test
  public void testTokenizeNewlineTrueAndSentenceSplitTwoSkipSingleNewline() {
    String text = "Êàë‰ª¨\nÂéªÂ≠¶Ê†°";
    AbstractSequenceClassifier<?> classifier = mock(AbstractSequenceClassifier.class);
    when(classifier.segmentString("Êàë‰ª¨ÂéªÂ≠¶Ê†°")).thenReturn(Arrays.asList("Êàë‰ª¨", "Âéª", "Â≠¶Ê†°"));
    Properties props =
        PropertiesUtils.asProperties(
            "segment.model",
            "dummy",
            StanfordCoreNLP.NEWLINE_IS_SENTENCE_BREAK_PROPERTY,
            "two",
            StanfordCoreNLP.NEWLINE_SPLITTER_PROPERTY,
            "true");
    ChineseSegmenterAnnotator annotator = new ChineseSegmenterAnnotator("segment", props);
    Annotation ann = new Annotation(text);
    CoreMap sentence = mock(CoreMap.class);
    when(sentence.get(CoreAnnotations.TextAnnotation.class)).thenReturn(text);
    ann.set(CoreAnnotations.SentencesAnnotation.class, Arrays.asList(sentence));
    ChineseSegmenterAnnotator spy = spy(annotator);
    // doReturn(classifier).when(spy).segmenter;
    spy.annotate(ann);
    verify(sentence)
        .set(
            eq(CoreAnnotations.TokensAnnotation.class),
            argThat(
                tokens -> {
                  return ((List<?>) tokens).size() == 3;
                }));
  }

  @Test
  public void testMakeXmlTokenNewlineNormalization() {
    String text = "\n";
    AbstractSequenceClassifier<?> classifier = mock(AbstractSequenceClassifier.class);
    when(classifier.segmentString("")).thenReturn(Collections.singletonList("\n"));
    Properties props =
        PropertiesUtils.asProperties(
            "segment.model", "dummy", StanfordCoreNLP.NEWLINE_SPLITTER_PROPERTY, "true");
    ChineseSegmenterAnnotator annotator = new ChineseSegmenterAnnotator("segment", props);
    Annotation ann = new Annotation(text);
    CoreMap sentence = mock(CoreMap.class);
    when(sentence.get(CoreAnnotations.TextAnnotation.class)).thenReturn(text);
    ann.set(CoreAnnotations.SentencesAnnotation.class, Collections.singletonList(sentence));
    ChineseSegmenterAnnotator spy = spy(annotator);
    // doReturn(classifier).when(spy).segmenter;
    spy.annotate(ann);
    verify(sentence)
        .set(
            eq(CoreAnnotations.TokensAnnotation.class),
            argThat(
                tokens -> {
                  List<CoreLabel> list = (List<CoreLabel>) tokens;
                  if (list.isEmpty()) return false;
                  for (CoreLabel t : list) {
                    if (t.word().equals("[CR]")
                        || t.word().equals("[NEWLINE]")
                        || System.lineSeparator().contains(t.word())) {
                      return true;
                    }
                  }
                  return false;
                }));
  }

  @Test
  public void testXmlTagEndsAtEndOfText() {
    String inputText = "<note>ÊèêÁ§∫</note>";
    AbstractSequenceClassifier<?> segmenter = mock(AbstractSequenceClassifier.class);
    when(segmenter.segmentString("ÊèêÁ§∫")).thenReturn(Collections.singletonList("ÊèêÁ§∫"));
    Properties props = PropertiesUtils.asProperties("segment.model", "dummy");
    ChineseSegmenterAnnotator annotator = new ChineseSegmenterAnnotator("segment", props);
    CoreMap sentence = mock(CoreMap.class);
    when(sentence.get(CoreAnnotations.TextAnnotation.class)).thenReturn(inputText);
    Annotation annotation = new Annotation(inputText);
    annotation.set(CoreAnnotations.SentencesAnnotation.class, Collections.singletonList(sentence));
    ChineseSegmenterAnnotator spy = spy(annotator);
    // doReturn(segmenter).when(spy).segmenter;
    spy.annotate(annotation);
    verify(sentence)
        .set(
            eq(CoreAnnotations.TokensAnnotation.class),
            argThat(
                tokens -> {
                  return ((List<?>) tokens).size() >= 2;
                }));
  }

  @Test
  public void testMultipleXmlBlocksMixedWithText() {
    String input = "<xml1>x</xml1>‰Ω†Â•Ω<xml2>y</xml2>";
    AbstractSequenceClassifier<?> segmenter = mock(AbstractSequenceClassifier.class);
    when(segmenter.segmentString("‰Ω†Â•Ω")).thenReturn(Arrays.asList("‰Ω†", "Â•Ω"));
    Properties props = PropertiesUtils.asProperties("segment.model", "dummy");
    ChineseSegmenterAnnotator annotator = new ChineseSegmenterAnnotator("segment", props);
    CoreMap sentence = mock(CoreMap.class);
    when(sentence.get(CoreAnnotations.TextAnnotation.class)).thenReturn(input);
    Annotation ann = new Annotation(input);
    ann.set(CoreAnnotations.SentencesAnnotation.class, Collections.singletonList(sentence));
    ChineseSegmenterAnnotator spy = spy(annotator);
    // doReturn(segmenter).when(spy).segmenter;
    spy.annotate(ann);
    verify(sentence)
        .set(
            eq(CoreAnnotations.TokensAnnotation.class),
            argThat(
                tokens -> {
                  List<?> list = (List<?>) tokens;
                  if (list.size() < 4) return false;
                  CoreLabel t1 = (CoreLabel) list.get(1);
                  return "‰Ω†".equals(t1.word());
                }));
  }

  @Test
  public void testCharacterOffsetsNonOverlapping() {
    String input = "Êó©‰∏äÂ•Ω";
    AbstractSequenceClassifier<?> segmenter = mock(AbstractSequenceClassifier.class);
    when(segmenter.segmentString("Êó©‰∏äÂ•Ω")).thenReturn(Arrays.asList("Êó©‰∏ä", "Â•Ω"));
    Properties props = PropertiesUtils.asProperties("segment.model", "dummy");
    ChineseSegmenterAnnotator a = new ChineseSegmenterAnnotator("segment", props);
    CoreMap sentence = mock(CoreMap.class);
    when(sentence.get(CoreAnnotations.TextAnnotation.class)).thenReturn(input);
    Annotation annotation = new Annotation(input);
    annotation.set(CoreAnnotations.SentencesAnnotation.class, Collections.singletonList(sentence));
    ChineseSegmenterAnnotator spy = spy(a);
    // doReturn(segmenter).when(spy).segmenter;
    spy.annotate(annotation);
    verify(sentence)
        .set(
            eq(CoreAnnotations.TokensAnnotation.class),
            argThat(
                tokens -> {
                  List<CoreLabel> list = (List<CoreLabel>) tokens;
                  if (list.size() != 2) return false;
                  Integer end0 =
                      list.get(0).get(CoreAnnotations.CharacterOffsetEndAnnotation.class);
                  Integer begin1 =
                      list.get(1).get(CoreAnnotations.CharacterOffsetBeginAnnotation.class);
                  return end0.equals(begin1);
                }));
  }

  @Test
  public void testTabsAreIgnoredLikeSpaces() {
    String input = "‰Ω†\tÊàë";
    AbstractSequenceClassifier<?> segmenter = mock(AbstractSequenceClassifier.class);
    when(segmenter.segmentString("‰Ω†Êàë")).thenReturn(Arrays.asList("‰Ω†", "Êàë"));
    Properties props = PropertiesUtils.asProperties("segment.model", "dummy");
    ChineseSegmenterAnnotator a = new ChineseSegmenterAnnotator("segment", props);
    CoreMap sentence = mock(CoreMap.class);
    when(sentence.get(CoreAnnotations.TextAnnotation.class)).thenReturn(input);
    Annotation ann = new Annotation(input);
    ann.set(CoreAnnotations.SentencesAnnotation.class, Collections.singletonList(sentence));
    ChineseSegmenterAnnotator spy = spy(a);
    // doReturn(segmenter).when(spy).segmenter;
    spy.annotate(ann);
    verify(sentence)
        .set(
            eq(CoreAnnotations.TokensAnnotation.class),
            argThat(
                tokens -> {
                  return ((List<?>) tokens).size() == 2;
                }));
  }

  @Test
  public void testSegmenterReturnsUnicodeSymbolTokens() {
    String input = "ÊàëÂñúüòäÊ¨¢";
    AbstractSequenceClassifier<?> segmenter = mock(AbstractSequenceClassifier.class);
    when(segmenter.segmentString("ÊàëÂñúüòäÊ¨¢")).thenReturn(Arrays.asList("Êàë", "Âñú", "üòä", "Ê¨¢"));
    Properties props = PropertiesUtils.asProperties("segment.model", "dummy");
    ChineseSegmenterAnnotator a = new ChineseSegmenterAnnotator("segment", props);
    CoreMap sentence = mock(CoreMap.class);
    when(sentence.get(CoreAnnotations.TextAnnotation.class)).thenReturn(input);
    Annotation ann = new Annotation(input);
    ann.set(CoreAnnotations.SentencesAnnotation.class, Collections.singletonList(sentence));
    ChineseSegmenterAnnotator spy = spy(a);
    // doReturn(segmenter).when(spy).segmenter;
    spy.annotate(ann);
    verify(sentence)
        .set(
            eq(CoreAnnotations.TokensAnnotation.class),
            argThat(
                tokens -> {
                  if (((List<?>) tokens).size() != 4) return false;
                  CoreLabel emoji = (CoreLabel) ((List<?>) tokens).get(2);
                  return "üòä".equals(emoji.word());
                }));
  }

  @Test
  public void testTextInsideXmlDoesNotTriggerSegmentation() {
    String input = "<tag>‰Ω†Â•ΩÂêó</tag>";
    AbstractSequenceClassifier<?> segmenter = mock(AbstractSequenceClassifier.class);
    when(segmenter.segmentString("")).thenReturn(Collections.emptyList());
    Properties props = PropertiesUtils.asProperties("segment.model", "dummy");
    ChineseSegmenterAnnotator annotator = new ChineseSegmenterAnnotator("segment", props);
    CoreMap sentence = mock(CoreMap.class);
    when(sentence.get(CoreAnnotations.TextAnnotation.class)).thenReturn(input);
    Annotation annotation = new Annotation(input);
    annotation.set(CoreAnnotations.SentencesAnnotation.class, Collections.singletonList(sentence));
    ChineseSegmenterAnnotator spy = spy(annotator);
    // doReturn(segmenter).when(spy).segmenter;
    spy.annotate(annotation);
    verify(sentence)
        .set(
            eq(CoreAnnotations.TokensAnnotation.class),
            argThat(
                tokens -> {
                  return ((List<?>) tokens).size() == 1;
                }));
  }

  @Test
  public void testXmlWhitespaceIsHandledAsSpecialFlag() {
    String input = "<tag> \t</tag>";
    AbstractSequenceClassifier<?> segmenter = mock(AbstractSequenceClassifier.class);
    when(segmenter.segmentString("")).thenReturn(Collections.emptyList());
    Properties props = PropertiesUtils.asProperties("segment.model", "dummy");
    ChineseSegmenterAnnotator a = new ChineseSegmenterAnnotator("segment", props);
    CoreMap sentence = mock(CoreMap.class);
    when(sentence.get(CoreAnnotations.TextAnnotation.class)).thenReturn(input);
    Annotation ann = new Annotation(input);
    ann.set(CoreAnnotations.SentencesAnnotation.class, Collections.singletonList(sentence));
    ChineseSegmenterAnnotator spy = spy(a);
    // doReturn(segmenter).when(spy).segmenter;
    spy.annotate(ann);
    verify(sentence)
        .set(
            eq(CoreAnnotations.TokensAnnotation.class),
            argThat(
                tokens -> {
                  return ((List<?>) tokens).size() == 1;
                }));
  }

  @Test
  public void testEmptyCoreLabelSegmentedWordIsSkipped() {
    String input = "Âåó‰∫¨";
    AbstractSequenceClassifier<?> segmenter = mock(AbstractSequenceClassifier.class);
    when(segmenter.segmentString("Âåó‰∫¨")).thenReturn(Arrays.asList("Âåó", "", "‰∫¨"));
    Properties props = PropertiesUtils.asProperties("segment.model", "dummy");
    ChineseSegmenterAnnotator a = new ChineseSegmenterAnnotator("segment", props);
    CoreMap sentence = mock(CoreMap.class);
    when(sentence.get(CoreAnnotations.TextAnnotation.class)).thenReturn(input);
    Annotation ann = new Annotation(input);
    ann.set(CoreAnnotations.SentencesAnnotation.class, Collections.singletonList(sentence));
    ChineseSegmenterAnnotator spy = spy(a);
    // doReturn(segmenter).when(spy).segmenter;
    spy.annotate(ann);
    verify(sentence)
        .set(
            eq(CoreAnnotations.TokensAnnotation.class),
            argThat(
                tokens -> {
                  List<?> list = (List<?>) tokens;
                  if (list.size() != 2) return false;
                  CoreLabel l1 = (CoreLabel) list.get(0);
                  CoreLabel l2 = (CoreLabel) list.get(1);
                  return "Âåó".equals(l1.word()) && "‰∫¨".equals(l2.word());
                }));
  }

  @Test
  public void testXmlRegionSingleCharWhitespaceBehavesCorrectly() {
    String input = "<xml> </xml>";
    AbstractSequenceClassifier<?> mockClassifier = mock(AbstractSequenceClassifier.class);
    when(mockClassifier.segmentString("")).thenReturn(Collections.emptyList());
    Properties props = PropertiesUtils.asProperties("segment.model", "dummy");
    ChineseSegmenterAnnotator annotator = new ChineseSegmenterAnnotator("segment", props);
    CoreMap sentence = mock(CoreMap.class);
    when(sentence.get(CoreAnnotations.TextAnnotation.class)).thenReturn(input);
    Annotation annotation = new Annotation(input);
    annotation.set(CoreAnnotations.SentencesAnnotation.class, Arrays.asList(sentence));
    ChineseSegmenterAnnotator spy = spy(annotator);
    // doReturn(mockClassifier).when(spy).segmenter;
    spy.annotate(annotation);
    verify(sentence)
        .set(
            eq(CoreAnnotations.TokensAnnotation.class),
            argThat(
                toks -> {
                  return ((List<?>) toks).size() == 1;
                }));
  }

  @Test
  public void testTokenizationRespectsUnicodeLineSeparatorU2028() {
    String input = "Êàë\u2028‰Ω†";
    AbstractSequenceClassifier<?> mockClassifier = mock(AbstractSequenceClassifier.class);
    when(mockClassifier.segmentString("Êàë‰Ω†")).thenReturn(Arrays.asList("Êàë", "‰Ω†"));
    Properties props =
        PropertiesUtils.asProperties(
            "segment.model", "dummy", StanfordCoreNLP.NEWLINE_SPLITTER_PROPERTY, "true");
    ChineseSegmenterAnnotator annotator = new ChineseSegmenterAnnotator("segment", props);
    CoreMap sentence = mock(CoreMap.class);
    when(sentence.get(CoreAnnotations.TextAnnotation.class)).thenReturn(input);
    Annotation annotation = new Annotation(input);
    annotation.set(CoreAnnotations.SentencesAnnotation.class, Arrays.asList(sentence));
    ChineseSegmenterAnnotator spy = spy(annotator);
    // doReturn(mockClassifier).when(spy).segmenter;
    spy.annotate(annotation);
    verify(sentence)
        .set(
            eq(CoreAnnotations.TokensAnnotation.class),
            argThat(
                toks -> {
                  List<CoreLabel> list = (List<CoreLabel>) toks;
                  return list.size() == 2;
                }));
  }

  @Test
  public void testCarriageReturnAloneIsRemoved() {
    String input = "‰ªäÂ§©Â§©Ê∞î\r‰∏çÈîô";
    AbstractSequenceClassifier<?> mockClassifier = mock(AbstractSequenceClassifier.class);
    when(mockClassifier.segmentString("‰ªäÂ§©Â§©Ê∞î‰∏çÈîô")).thenReturn(Arrays.asList("‰ªäÂ§©Â§©Ê∞î", "‰∏çÈîô"));
    Properties props = PropertiesUtils.asProperties("segment.model", "dummy");
    ChineseSegmenterAnnotator annotator = new ChineseSegmenterAnnotator("segment", props);
    CoreMap sentence = mock(CoreMap.class);
    when(sentence.get(CoreAnnotations.TextAnnotation.class)).thenReturn(input);
    Annotation annotation = new Annotation(input);
    annotation.set(CoreAnnotations.SentencesAnnotation.class, Arrays.asList(sentence));
    ChineseSegmenterAnnotator spy = spy(annotator);
    // doReturn(mockClassifier).when(spy).segmenter;
    spy.annotate(annotation);
    verify(sentence)
        .set(
            eq(CoreAnnotations.TokensAnnotation.class),
            argThat(
                toks -> {
                  List<CoreLabel> list = (List<CoreLabel>) toks;
                  return list.size() == 2;
                }));
  }

  @Test
  public void testMultipleNewlinesArePreservedWhenConfigured() {
    String input = "‰∏ÄÂè•ËØù\n\n\nÁ¨¨‰∫åÂè•ËØù";
    AbstractSequenceClassifier<?> mockClassifier = mock(AbstractSequenceClassifier.class);
    when(mockClassifier.segmentString("‰∏ÄÂè•ËØùÁ¨¨‰∫åÂè•ËØù")).thenReturn(Arrays.asList("‰∏ÄÂè•ËØù", "Á¨¨‰∫åÂè•ËØù"));
    Properties props =
        PropertiesUtils.asProperties(
            "segment.model", "dummy", StanfordCoreNLP.NEWLINE_SPLITTER_PROPERTY, "true");
    ChineseSegmenterAnnotator annotator = new ChineseSegmenterAnnotator("segment", props);
    CoreMap sentence = mock(CoreMap.class);
    when(sentence.get(CoreAnnotations.TextAnnotation.class)).thenReturn(input);
    Annotation ann = new Annotation(input);
    ann.set(CoreAnnotations.SentencesAnnotation.class, Collections.singletonList(sentence));
    ChineseSegmenterAnnotator spy = spy(annotator);
    // doReturn(mockClassifier).when(spy).segmenter;
    spy.annotate(ann);
    verify(sentence)
        .set(
            eq(CoreAnnotations.TokensAnnotation.class),
            argThat(
                toks -> {
                  List<CoreLabel> list = (List<CoreLabel>) toks;
                  if (list.size() < 3) return false;
                  CoreLabel newlineToken = list.get(1);
                  String orig = newlineToken.originalText();
                  return orig != null && orig.contains("\n");
                }));
  }

  @Test
  public void testSegmentationSkipsSingleNewlinesWhenSplittingOnTwoNewlines() {
    String input = "Êàë\n‰Ω†";
    AbstractSequenceClassifier<?> mockClassifier = mock(AbstractSequenceClassifier.class);
    when(mockClassifier.segmentString("Êàë‰Ω†")).thenReturn(Arrays.asList("Êàë", "‰Ω†"));
    Properties props =
        PropertiesUtils.asProperties(
            "segment.model",
            "dummy",
            StanfordCoreNLP.NEWLINE_IS_SENTENCE_BREAK_PROPERTY,
            "two",
            StanfordCoreNLP.NEWLINE_SPLITTER_PROPERTY,
            "true");
    ChineseSegmenterAnnotator annotator = new ChineseSegmenterAnnotator("segment", props);
    CoreMap sentence = mock(CoreMap.class);
    when(sentence.get(CoreAnnotations.TextAnnotation.class)).thenReturn(input);
    Annotation ann = new Annotation(input);
    ann.set(CoreAnnotations.SentencesAnnotation.class, Collections.singletonList(sentence));
    ChineseSegmenterAnnotator spy = spy(annotator);
    // doReturn(mockClassifier).when(spy).segmenter;
    spy.annotate(ann);
    verify(sentence)
        .set(
            eq(CoreAnnotations.TokensAnnotation.class),
            argThat(
                toks -> {
                  return ((List<?>) toks).size() == 2;
                }));
  }

  @Test
  public void testInvalidSegmentedTokenThrowsAdvancePosError() {
    String input = "ab";
    CoreLabel cl0 = new CoreLabel();
    cl0.set(CoreAnnotations.ChineseCharAnnotation.class, "a");
    CoreLabel cl1 = new CoreLabel();
    cl1.set(CoreAnnotations.ChineseCharAnnotation.class, "b");
    List<CoreLabel> chars = new ArrayList<>();
    chars.add(cl0);
    chars.add(cl1);
    try {
      ChineseSegmenterAnnotator.class
          .getDeclaredMethod("advancePos", List.class, int.class, String.class)
          .invoke(null, chars, 0, "abc");
      fail("Expected RuntimeException");
    } catch (Exception e) {
      Throwable cause = e.getCause();
      assertNotNull(cause);
      assertTrue(cause instanceof RuntimeException);
    }
  }

  @Test
  public void testSingleCharacterNotSplitFurther() {
    String text = "Âêó";
    AbstractSequenceClassifier<?> classifier = mock(AbstractSequenceClassifier.class);
    when(classifier.segmentString("Âêó")).thenReturn(Collections.singletonList("Âêó"));
    Properties props = PropertiesUtils.asProperties("segment.model", "dummy");
    ChineseSegmenterAnnotator annotator = new ChineseSegmenterAnnotator("segment", props);
    CoreMap sentence = mock(CoreMap.class);
    when(sentence.get(CoreAnnotations.TextAnnotation.class)).thenReturn(text);
    Annotation annotation = new Annotation(text);
    annotation.set(CoreAnnotations.SentencesAnnotation.class, Collections.singletonList(sentence));
    ChineseSegmenterAnnotator spy = spy(annotator);
    // doReturn(classifier).when(spy).segmenter;
    spy.annotate(annotation);
    verify(sentence)
        .set(
            eq(CoreAnnotations.TokensAnnotation.class),
            argThat(
                tokens -> {
                  return ((List<?>) tokens).size() == 1;
                }));
  }

  @Test
  public void testLeadingAndTrailingSpacesAreSkippedWhenNewlineSplitDisabled() {
    String input = "  ÊàëÂñúÊ¨¢‰∏≠Êñá  ";
    AbstractSequenceClassifier<?> classifier = mock(AbstractSequenceClassifier.class);
    when(classifier.segmentString("ÊàëÂñúÊ¨¢‰∏≠Êñá")).thenReturn(Arrays.asList("Êàë", "ÂñúÊ¨¢", "‰∏≠Êñá"));
    Properties props = PropertiesUtils.asProperties("segment.model", "dummy");
    ChineseSegmenterAnnotator annotator = new ChineseSegmenterAnnotator("segment", props);
    CoreMap sentence = mock(CoreMap.class);
    when(sentence.get(CoreAnnotations.TextAnnotation.class)).thenReturn(input);
    Annotation annotation = new Annotation(input);
    annotation.set(CoreAnnotations.SentencesAnnotation.class, Collections.singletonList(sentence));
    ChineseSegmenterAnnotator spy = spy(annotator);
    // doReturn(classifier).when(spy).segmenter;
    spy.annotate(annotation);
    verify(sentence)
        .set(
            eq(CoreAnnotations.TokensAnnotation.class),
            argThat(
                tokens -> {
                  List<CoreLabel> list = (List<CoreLabel>) tokens;
                  return list.size() == 3;
                }));
  }

  @Test
  public void testSingleNewlinePreservedIfNotLeadingOrTrailing() {
    String input = "Êàë\n‰Ω†";
    AbstractSequenceClassifier<?> classifier = mock(AbstractSequenceClassifier.class);
    when(classifier.segmentString("Êàë‰Ω†")).thenReturn(Arrays.asList("Êàë", "‰Ω†"));
    Properties props =
        PropertiesUtils.asProperties(
            "segment.model", "dummy", StanfordCoreNLP.NEWLINE_SPLITTER_PROPERTY, "true");
    ChineseSegmenterAnnotator annotator = new ChineseSegmenterAnnotator("segment", props);
    CoreMap sentence = mock(CoreMap.class);
    when(sentence.get(CoreAnnotations.TextAnnotation.class)).thenReturn(input);
    Annotation ann = new Annotation(input);
    ann.set(CoreAnnotations.SentencesAnnotation.class, Collections.singletonList(sentence));
    ChineseSegmenterAnnotator spy = spy(annotator);
    // doReturn(classifier).when(spy).segmenter;
    spy.annotate(ann);
    verify(sentence)
        .set(
            eq(CoreAnnotations.TokensAnnotation.class),
            argThat(
                tokens -> {
                  List<CoreLabel> list = (List<CoreLabel>) tokens;
                  if (list.size() != 3) return false;
                  CoreLabel newline = list.get(1);
                  String word = newline.word();
                  return "\n".equals(newline.originalText())
                      || "[CR]".equals(word)
                      || word.contains("\n");
                }));
  }
}
